{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Coding an AutoEncoder in Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The AutoEncoder network is a network architecture that aims to compress a high dimensional input vector to a vector in a lower dimensional space (encoding). In order to do so the network compresses and decompresses the input during the learning process.\n",
    "\n",
    "![Center](images/ae_arch.png)\n",
    "\n",
    " We call the input of the network $X$ and the output $X'$. The train the network to obtain the optimal compression, i.e. when the difference between the input $X$ and the decompressed output $X'$ is minimum.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Let's first import some useful libraries, and define the Leaky_ReLU function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "def lrelu(X, alpha=0.1):\n",
    "    return tf.maximum(alpha*X, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "Let's also import the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, _), (X_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and draw a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sample: \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAABOhJREFUeJzt3bGOTVscwOG7r6uhkxAdlYyEIFFISDQq0WhVHkDiPbQeQSWZRCFCS6mhFJVCRaEiGrYXmLMmd86ZM+P8vq88/6zZq/llJbNyzp7mef4H2Hz/HvQGgPUQO0SIHSLEDhFih4j/1vmwaZr86x/22TzP006fO9khQuwQIXaIEDtEiB0ixA4RYocIsUOE2CFC7BAhdogQO0SIHSLEDhFihwixQ4TYIULsECF2iBA7RIgdIsQOEWKHCLFDhNghQuwQIXaIEDtEiB0ixA4Ra31lMz3nzp1bOPvw4cNw7cOHD4fzx48f72lPVU52iBA7RIgdIsQOEWKHCLFDhNghwj07++rKlSsLZ79//x6u/fz586q3k+ZkhwixQ4TYIULsECF2iBA7RIgdItyzs68uX768cPb9+/fh2mfPnq16O2lOdogQO0SIHSLEDhFihwixQ4SrN5Zy4cKF4fzBgwcLZ0+ePFn1dhhwskOE2CFC7BAhdogQO0SIHSLEDhHu2VnK1tbWcH78+PGFs6dPn656Oww42SFC7BAhdogQO0SIHSLEDhFih4hpnuf1PWya1vcw1uLt27fD+cmTJxfOdvsu/G4/Nc3O5nmedvrcyQ4RYocIsUOE2CFC7BAhdogQO0T4PjtDZ8+eHc6vXr06nH/8+HHhzD36ejnZIULsECF2iBA7RIgdIsQOEWKHCPfsDN28eXOp9V+/fl3RTliWkx0ixA4RYocIsUOE2CFC7BDh6o2hixcvLrX+0aNHK9oJy3KyQ4TYIULsECF2iBA7RIgdIsQOEV7ZHHft2rXh/MWLF8P5p0+fhvPr168vnP38+XO4lr3xymaIEztEiB0ixA4RYocIsUOE2CHC99njbt26NZyfOHFiOH/16tVw7i798HCyQ4TYIULsECF2iBA7RIgdIsQOEe7Z4y5dujSc7/Z7B9vb26vcDvvIyQ4RYocIsUOE2CFC7BAhdogQO0T43fgNd/r06eH8/fv3w/m3b9+G8/Pnz//vPbG//G48xIkdIsQOEWKHCLFDhNghwldcN9z9+/eH81OnTg3nL1++XOFuOEhOdogQO0SIHSLEDhFihwixQ4TYIcI9+4Y7c+bMUut3+4orfw8nO0SIHSLEDhFihwixQ4TYIULsEOGefcPduXNnqfXPnz9f0U44aE52iBA7RIgdIsQOEWKHCLFDhNghwj37Brhx48bC2W6vbKbDyQ4RYocIsUOE2CFC7BAhdohw9bYB7t69u3B25MiR4dp3794N52/evNnTnjh8nOwQIXaIEDtEiB0ixA4RYocIsUOEe/a/wLFjx4bz27dv7/lvb29vD+e/fv3a89/mcHGyQ4TYIULsECF2iBA7RIgdIsQOEdM8z+t72DSt72Eb5OjRo8P569evF86+fPkyXHvv3r3h/MePH8M5h888z9NOnzvZIULsECF2iBA7RIgdIsQOEWKHCPfssGHcs0Oc2CFC7BAhdogQO0SIHSLEDhFihwixQ4TYIULsECF2iBA7RIgdIsQOEWKHCLFDhNghQuwQIXaIEDtEiB0ixA4RYocIsUOE2CFC7BAhdogQO0SIHSLW+spm4OA42SFC7BAhdogQO0SIHSLEDhFihwixQ4TYIULsECF2iBA7RIgdIsQOEWKHCLFDhNghQuwQIXaIEDtEiB0ixA4RYoeIP8ieku2KR0d8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = 2 #chose one sample in the training set\n",
    "\n",
    "X_train = X_train.astype(np.float32).reshape(-1,28*28)/X_train.max()\n",
    "X_test = X_test.astype(np.float32).reshape(-1,28*28)/X_train.max()\n",
    "\n",
    "print('\\n Sample: \\n')\n",
    "plt.imshow(X_test[sample].reshape(28,28), cmap='gray');\n",
    "plt.axis('off');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Layer class definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class provides the definition of a dense layer. A dense layer is characterized by its trainable weights:\n",
    "\n",
    "- a matrix W of dimensions (m_input, m_output)\n",
    "- a bias vector b of dimensions (m_output)\n",
    "\n",
    "The Layer class possesses the ```forward``` method which performs the linear forward propagation:\n",
    "\n",
    "$$\n",
    "Z_{out}= X_{in} \\times W(m_{in},m_{out})+b(m_{out})\n",
    "$$\n",
    "\n",
    "Code along with us and follow the provided instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    \n",
    "    def __init__(self, mi, mo, name):\n",
    "        \n",
    "        \"\"\"\n",
    "        This is the init method of the class Layer:\n",
    "        It defines the class itself and contains the\n",
    "        definition of the parameters that will be used by\n",
    "        the other class' methods (i.e. forward)\n",
    "        \n",
    "        \"\"\"\n",
    "        # we are creating a dense layer, it's trainable parameters\n",
    "        # are the matrix W of dimensions (mi, mo) and the biases\n",
    "        # vectors that has dimension (mo)\n",
    "        \n",
    "        # this name identifies uniquely the matrix W\n",
    "        # this assigns to the matrix the needed shape\n",
    "        # you can choose among\n",
    "        # many different distributions\n",
    "        # to initialize your weights with\n",
    "        \n",
    "        # this name identifies uniquely the bias vector b \n",
    "                \n",
    "       # biases can be initialized as zeros\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        \"\"\"\n",
    "        This is the forward propagation method of the class Layer\n",
    "        \"\"\"\n",
    "        # the method forward performs the following forward propagation \n",
    "        # operation on the input tensor X. Don't worry about back  \n",
    "        # propagation, tensorflow will handle it\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Creating the AutoEncoder Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build the AutoEncoder as a class possessing several methods:\n",
    "\n",
    "```\n",
    "class AutoEncoder():\n",
    "\n",
    "    def __init__():\n",
    "    \n",
    "    def build_network():\n",
    "    \n",
    "    def decode():\n",
    "    \n",
    "    def encode():\n",
    "    \n",
    "    def fit():\n",
    "    \n",
    "```\n",
    "\n",
    "Code along with us and follow the provided instructions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(object):\n",
    "    \n",
    "    def __init__():\n",
    "        \n",
    "        # Note: all of what has self in front of it will be reused outside the init method!\n",
    "        #       thus we make promote some constants to attributes of the class\n",
    "        \n",
    "        \"\"\"\n",
    "        The AutoEncoder (AE) class is initialized by providing the number of features of the \n",
    "        input (in this case 28*28) and a list of integers named layers_dims.\n",
    "        It contains the number of the nodes for the intermediate layers and is of the kind:\n",
    "        \n",
    "        layer_dims= [\n",
    "                     output_nodes_layer_1,\n",
    "                     output_nodes_layer_2,\n",
    "                     output_nodes_layer_3,\n",
    "                     ...\n",
    "                     output_nodes_layer_n\n",
    "                     ]\n",
    "                     \n",
    "        \"\"\"\n",
    "        # Write code here\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        The AE architecture has a butterfly shape and thus we reverse the previous \n",
    "        list of shapes to obtain:\n",
    "        \n",
    "        reversed_layer_dims = [\n",
    "                               output_nodes_layer_(n-1),\n",
    "                               output_nodes_layer_(n-2),\n",
    "                               ...\n",
    "                               output_nodes_layer_2,\n",
    "                               output_nodes_layer_1,\n",
    "                               ]\n",
    "        \"\"\"\n",
    "        # Write code here\n",
    "        # Note: Exclude layer n\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        Now we define the placeholder for our input tensor X_in, and create 2 empty lists\n",
    "        named encoder_layers and decoder_layers that will contain the layers of our AE\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #Write code here\n",
    "\n",
    "                \n",
    "        \"\"\"\n",
    "        \n",
    "        We miss one last ingredient to build our AE: a method that builds the network ,\n",
    "        it will be called build_network\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        # Write code here\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Let's define what this build network method does:\n",
    "    \n",
    "    \"\"\"\n",
    "    def build_network(self, input_dim):\n",
    "        \n",
    "        \"\"\"\n",
    "        STEP 1: BUILDING THE NETWORK\n",
    "        \n",
    "        the method build_network creates the graph that represents the network. It \n",
    "        does this by making use of two for loops, the first defines the encoder layers\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        ENCODER LAYERS\n",
    "        \"\"\"\n",
    "        # Write code here\n",
    "        #input size\n",
    "        #set a counter for layers' names\n",
    "        \n",
    "        # loop over a list [mo_1, mo_2, ..., mo_(n-1), mo_n]\n",
    "        # of intermediate layer dimensions\n",
    "        \n",
    "        # for each intermediate layer dimension create a layer\n",
    "        # named 'count' with associated weights of shape W(mi, mo) b(mo)\n",
    "        \n",
    "        # add the created layer to the list of encoder layers\n",
    "        # and increase the counter\n",
    "        # the input dimension mi of the next layer will be the ouput\n",
    "        # dimension of the previous one\n",
    "        \n",
    "        #Note: in this way the class is created independently of the size of the network! the actual\n",
    "        #      list of layer dimensions is given later!\n",
    "            \n",
    "        \"\"\"\n",
    "        DECODER LAYERS\n",
    "        \"\"\"\n",
    "        # We repeat the same operations, but in reverse order to create the right hand-side of the butterfly\n",
    "        # the decoder\n",
    "        \n",
    "        #Write code here\n",
    "        # loop over a list [mo_(n-1), mo_(n-2), ..., mo_2, mo_1]  \n",
    "        \n",
    "        # create the layer here\n",
    "        \n",
    "        # append the layer to the decoder layers list\n",
    "        # increase the counter and\n",
    "        # update the output dimensions\n",
    "            \n",
    "        # Note that the last mo is not the input size, so, to compare\n",
    "        # the input of the network with the ouput \n",
    "        \n",
    "        # we'll have to create one last layer\n",
    "        # of dimensions (mi, input_dim):\n",
    "        # and append it to the list of decoder layers\n",
    "        \n",
    "    \n",
    "        \"\"\"\n",
    "        \n",
    "        STEP 2: BUILDING THE GRAPH\n",
    "        \n",
    "        Now that the network has been built, we want to \n",
    "        define how the input will propagate through the encoder and the decoder.\n",
    "        \n",
    "        The overall forward propagation of each side of the network is\n",
    "        the propagation through each single layer and is carried out by the\n",
    "        \"encode\" and \"decode\" functions:\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "        # Propagation of the input through the encoder. \n",
    "        # This outputs the latent vector self.Z\n",
    "        \n",
    "        # Propagation of the latent vector self.Z\n",
    "        # through the decoder, last output is unactivated \n",
    "        # on purpose (will be clearer later)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        STEP 3: DEFINING THE LOSS and THE OPTIMIZATION ALGORITHM\n",
    "        \n",
    "        With the two last steps we created the network and the graph of operations\n",
    "        that propagate the input until the network output X_hat. Now we have to define\n",
    "        The loss function, i.e. that positive number, function of the network\n",
    "        parameters that has to be minimized during training.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        LOSS\n",
    "        \"\"\"\n",
    "        \n",
    "        # write code here\n",
    "        # reduce_sum converts a tensor to a scalar sum of its components\n",
    "                    \n",
    "        \"\"\"\n",
    "        \n",
    "        OPTIMIZATION ALGORITHM\n",
    "        \n",
    "        Define the loss minimization algorithm, we chose Adaptive momentum optimizer (Adam) for \n",
    "        this purpose. Everytime train_op will be called, one step of gradient minimization will\n",
    "        be taken.\n",
    "        \"\"\"\n",
    "        # write code here\n",
    "        \n",
    "                                                #set the learning rate                #what to minimize\n",
    "        \n",
    "    \"\"\"\n",
    "    We now define the last two functions: encode and decode which we used previously\n",
    "    in STEP 2 \n",
    "    \"\"\"\n",
    "    # write code here\n",
    "    def encode(self, X):                                # This method takes as input a sample X\n",
    "    # and outputs its encoded form Z\n",
    "    \n",
    "    \n",
    "    \n",
    "    # This loop propagates the input X\n",
    "    # through the encoder layers using\n",
    "    # their forward method\n",
    "    \n",
    "    \n",
    "    # vector in latent space, Z\n",
    "        \n",
    "    def decode(self,Z):                                 # This method takes a vector Z in the \n",
    "    # latent space and decodes it to X_hat\n",
    "    # living in the space of the samples\n",
    "   \n",
    "   \n",
    "    # Loop through the decoder network,  \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "    \n",
    "    def fit(self, X, show_fig=True):                    # Fit method of the class AutoEncoder\n",
    "         \n",
    "        losses = []                                     # a list containing the losses\n",
    "        n_batches = len(X) // self.batch_size\n",
    "        \n",
    "        print(\"Training AutoEncoder\")\n",
    "        print(\"n_batches:\", n_batches)\n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            print(\"epoch:\", i)\n",
    "            np.random.shuffle(X)\n",
    "        \n",
    "            for j in range(n_batches):                  # the training cycle in one epoch:\n",
    "            \n",
    "                X_batch = X[j*self.batch_size:(j+1)*self.batch_size] # the batch to pass for computation\n",
    "                _, l, = self.session.run((self.train_op, self.loss), \n",
    "                                         feed_dict={self.X_in: X_batch}) #running one step of gradient\n",
    "                l /= self.batch_size                                     #minimization\n",
    "\n",
    "                losses.append(l)\n",
    "                \n",
    "                # let's add some intermediate printouts to see how the training is going\n",
    "                if j % 80*self.batch_size == 0:        \n",
    "\n",
    "                    print(\"iter: %d, cost: %.3f\" % (j, l))\n",
    "            \n",
    "        if show_fig:                                   # Plotting the loss as a function\n",
    "            plt.plot(losses)                           # \n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    def predict(self, X):                              # function to test the network once training\n",
    "                                                       # is completed\n",
    "        \n",
    "        return self.session.run(self.X_hat, feed_dict={self.X_in: X})\n",
    "\n",
    "\n",
    "    def set_session(self, session):\n",
    "        \n",
    "        self.session = session\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Test the AutoEncoder\n",
    "\n",
    "Now that the AutoEncoder class is defined, we create our own AutoEncoder and test how it works. As usual follow our coding and use the provided instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AutoEncoder\n",
      "n_batches: 600\n",
      "epoch: 0\n",
      "iter: 0, cost: 188.702\n",
      "iter: 80, cost: 51.037\n",
      "iter: 160, cost: 41.579\n",
      "iter: 240, cost: 34.287\n",
      "iter: 320, cost: 32.560\n",
      "iter: 400, cost: 29.643\n",
      "iter: 480, cost: 26.655\n",
      "iter: 560, cost: 24.269\n",
      "epoch: 1\n",
      "iter: 0, cost: 22.839\n",
      "iter: 80, cost: 21.699\n",
      "iter: 160, cost: 20.652\n",
      "iter: 240, cost: 17.404\n",
      "iter: 320, cost: 19.206\n",
      "iter: 400, cost: 17.753\n",
      "iter: 480, cost: 16.224\n",
      "iter: 560, cost: 17.389\n",
      "epoch: 2\n",
      "iter: 0, cost: 15.498\n",
      "iter: 80, cost: 13.698\n",
      "iter: 160, cost: 14.674\n",
      "iter: 240, cost: 14.183\n",
      "iter: 320, cost: 12.349\n",
      "iter: 400, cost: 13.080\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-f410b19b0ee2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mdae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Set it for the AutoEncoder you defined previously\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mdae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# Call the fit method that you defined previously\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-e54a6d1655dc>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, show_fig)\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# the batch to pass for computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 _, l, = self.session.run((self.train_op, self.loss), \n\u001b[0;32m--> 226\u001b[0;31m                                          feed_dict={self.X_in: X_batch}) #running one step of gradient\n\u001b[0m\u001b[1;32m    227\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m                                     \u001b[0;31m#minimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lets get the input_dimensions from the dataset\n",
    "# Resetting any previously defined graph\n",
    "\n",
    "\"\"\"\n",
    "Create the AutoEncoder object\n",
    "\n",
    "dae = AutoEncoder() \n",
    "\n",
    "with aruguments it\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#write code here                \n",
    "# Create your very own network here!!\n",
    "\n",
    "# Play with the layers' list, it will \n",
    "# automatically define the intermediate\n",
    "# layers.\n",
    "\n",
    "# Set some values for the learning rate\n",
    "# the epochs and the batch_size\n",
    "\n",
    "\n",
    "\n",
    "# Define the network's variables initializer\n",
    "\n",
    "\n",
    "\n",
    "# Create a tensorflow session\n",
    "\n",
    "# Initialize the network variables in this sess\n",
    "# Set it for the AutoEncoder you defined previously\n",
    "\n",
    "# Call the fit method that you defined previously\n",
    "    \n",
    "\n",
    "    # Testing the created network performances on the test set!\n",
    "    done = False\n",
    "    while not done:\n",
    "        i = np.random.choice(len(X_test))         # pick a random sample of the test set\n",
    "        x = X_test[i]                             \n",
    "        y = dae.predict([x]).reshape(28, 28)      # propagate it through the network\n",
    "\n",
    "        plt.subplot(1,2,1)                        # Plot the original and the reconstructed\n",
    "        plt.imshow(x.reshape(28, 28), cmap='gray')\n",
    "        plt.title(\"Original\")\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(y, cmap='gray')\n",
    "        plt.title(\"Reconstruction\")\n",
    "        plt.show()\n",
    "\n",
    "        ans = input(\"Generate another?\")          # Stop the while loop with 'n' or 'N'\n",
    "        if ans and ans[0] in ('n' or 'N'):\n",
    "              done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
